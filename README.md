# About the Project
This project is a machine learning project based on the binary classifcation of light curves from the Kepler telescope. The Kepler telescope ran from 2009 to 2018 and its main goal was to find Earth-sized exoplanets. It collected the brightness of ~150,000 stars over its time in service and from the change in brightness of a star, NASA was able to determine if a star had an exoplanet in its system. I used the NASA Exoplanet Archive to download light curves generated by the Kepler telescope to train 6 different algorithms to try and determine if a light curve was indicative of an exoplanet: KNN, Naive Bayes, LSTM, MLP, GRU, and CNN.

<p align="center">
  <img src="https://user-images.githubusercontent.com/112229422/235833110-6c573a9a-6c1a-4fa8-b407-40d486e4fab7.png" alt="lightcuve"/>
</p>

# Purpose
One of the topics for my semester project in my Intro to AI class was signal classification. Rather than do the project with a well curated dataset on a topic I didn't care much for, I wanted to work with a messy data set in a field that I love and have had interest in since I was a kid! After some digging, I found that this dataset has been used in other academic papers so I had a jumping off point and there was a library already built for it in Python, which made things so much easier.

# Overview
The project itself consists of three parts: retrieval of the data set, training of algorithms, and prediction.
 - Data Set: From the Exoplanet Archive, I downloaded a master CSV (called keplerDataset) that contains a large list of stars, information about the star, and whether or not an exoplanet was CONFIRMED, a FALSE POSITIVE, or a CANDIDATE. For ease of binary classification, I removed all stars labled as CANDIDATE. I then wrote a program to loop through this list and download simple light curve files for ~1000 stars and also calculate pertinent info about the light curve including max flux, min flux, average flux, max to min flux, and flux variance. It often bogged down or disconnected from the Archive so this is why only 1000 were used.
 - Training: Once the data was retrieved, I then built and trained the 6 different algorithms from above. These specific ones were used as they were the stipulations for the project but I hope to add more in the future. For the tradiational classifiers, the calculated info was used in the training of those and for the neural networks, the raw light curve photo was passed in. The data was split into 80/20 training/validation.
 - Prediction: The Driver file allows you to run the prediction part of the program. The first option in the menu allows the user to see the accuracy of each of the models from a random sample of 200 curve. The second option allows the user to type in an index of the keplerDataset CSV, generate a curve, and show the predictions of all 6 algorithms.
